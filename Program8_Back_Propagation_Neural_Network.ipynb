{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shravani0491/ML-LAB/blob/main/Program8_Back_Propagation_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F18285%2F23917%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240523%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240523T060958Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7d4aa4790738b831d17de9b609a0fa20896b179546c94c5e917b7f2919499b8dc4058f94fe7d870ece8b36220454b40390edb898b7c794d7e3b1b9c082dcbbaddcd9231bbf0dec73b604d4a82795247c9509f61eb89e8bba00ed7a22c489a7ff0775fed2e8fdf2636677850d23d2757ad47ab8cbc2dba6ebac42a9a3ae405bae9084d4731fb00089379c84c76fd319bb2495513b1da680663f81c5114e5bcd2556748d7a41347733485b176fdbbbb1cbaed96b02125baa78dba9cb7e64f5e3bed8ed70a157da9e4d257c679508f48cba24141c3f1726b873ef227e08fecb53af3a7da91359f32a73825263079e8d83b2595a5889426c50853be90da1d049176a'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "A-WM0CDgEhev",
        "outputId": "03ee9a70-d75c-4e9c-c36c-a8bca734e9a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading , 2350669 bytes compressed\n",
            "[==================================================] 2350669 bytes downloaded\n",
            "Downloaded and uncompressed: \n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "collapsed": true,
        "trusted": false,
        "id": "IjPl8zsIEhey",
        "outputId": "d5e94e83-0f0c-4d6e-a6a7-7ef3885562ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "db = np.loadtxt(\"../input/duke-breast-cancer.txt\")\n",
        "print(\"Database raw shape (%s,%s)\" % np.shape(db))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database raw shape (86,7130)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "762d37c4dae44319c9d2422e169d7ea0f33572a9",
        "_cell_guid": "24bea183-2074-4d53-a47a-cf05bb5ec7ed",
        "collapsed": true,
        "trusted": false,
        "id": "WDIjmA4HEhez",
        "outputId": "db954255-696a-4c73-d612-cfd062420215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.shuffle(db)\n",
        "y = db[:, 0]\n",
        "x = np.delete(db, [0], axis=1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "print(np.shape(x_train),np.shape(x_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(77, 7129) (9, 7129)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c6e92169cd8d40cfbd6535d89ef9d568ec7f080a",
        "_cell_guid": "c56476bc-9ed6-4f59-adcc-05c1d7efffe8",
        "collapsed": true,
        "trusted": false,
        "id": "kpiS7bnHEhez"
      },
      "cell_type": "code",
      "source": [
        "hidden_layer = np.zeros(72)\n",
        "weights = np.random.random((len(x[0]), 72))\n",
        "output_layer = np.zeros(2)\n",
        "hidden_weights = np.random.random((72, 2))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a9363b0d1930d5ab7bf109087c44f9f1f5378e04",
        "_cell_guid": "64eef7a8-6c64-41c9-857b-8719e740acb9",
        "collapsed": true,
        "trusted": false,
        "id": "LefmBJLUEhe0"
      },
      "cell_type": "code",
      "source": [
        "def sum_function(weights, index_locked_col, x):\n",
        "    result = 0\n",
        "    for i in range(0, len(x)):\n",
        "        result += x[i] * weights[i][index_locked_col]\n",
        "    return result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4d8da27a9d20a0d9e22ccbc7f2e97a2ad1ce3d8d",
        "_cell_guid": "6c9963c8-0c5b-4b5d-8254-940017be5147",
        "collapsed": true,
        "trusted": false,
        "id": "EmW6i8hgEhe0"
      },
      "cell_type": "code",
      "source": [
        "def activate_layer(layer, weights, x):\n",
        "    for i in range(0, len(layer)):\n",
        "        layer[i] = 1.7159 * np.tanh(2.0 * sum_function(weights, i, x) / 3.0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cd1e82c77d052992d5b8bfe9ea4793c7dae9fa82",
        "_cell_guid": "c33b200b-07e1-475a-9310-4b6486f36f46",
        "collapsed": true,
        "trusted": false,
        "id": "5fyg4y7XEhe0"
      },
      "cell_type": "code",
      "source": [
        "def soft_max(layer):\n",
        "    soft_max_output_layer = np.zeros(len(layer))\n",
        "    for i in range(0, len(layer)):\n",
        "        denominator = 0\n",
        "        for j in range(0, len(layer)):\n",
        "            denominator += np.exp(layer[j] - np.max(layer))\n",
        "        soft_max_output_layer[i] = np.exp(layer[i] - np.max(layer)) / denominator\n",
        "    return soft_max_output_layer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a2d58312392a090b6f9c07b4c251bfae866aaefa",
        "_cell_guid": "8ee9f8b5-35a4-4a20-85b6-e13fc2c16db8",
        "collapsed": true,
        "trusted": false,
        "id": "-l033SaXEhe0"
      },
      "cell_type": "code",
      "source": [
        "def recalculate_weights(learning_rate, weights, gradient, activation):\n",
        "    for i in range(0, len(weights)):\n",
        "        for j in range(0, len(weights[i])):\n",
        "            weights[i][j] = (learning_rate * gradient[j] * activation[i]) + weights[i][j]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf147c36b5709607dad90ab78749a77dea18f0d6",
        "_cell_guid": "886bcb3a-4b24-4d2c-bb93-a932a0e5e5bf",
        "collapsed": true,
        "trusted": false,
        "id": "EaGvEc5fEhe1"
      },
      "cell_type": "code",
      "source": [
        "def back_propagation(hidden_layer, output_layer, one_hot_encoding, learning_rate, x):\n",
        "    output_derivative = np.zeros(2)\n",
        "    output_gradient = np.zeros(2)\n",
        "    for i in range(0, len(output_layer)):\n",
        "        output_derivative[i] = (1.0 - output_layer[i]) * output_layer[i]\n",
        "    for i in range(0, len(output_layer)):\n",
        "        output_gradient[i] = output_derivative[i] * (one_hot_encoding[i] - output_layer[i])\n",
        "    hidden_derivative = np.zeros(72)\n",
        "    hidden_gradient = np.zeros(72)\n",
        "    for i in range(0, len(hidden_layer)):\n",
        "        hidden_derivative[i] = (1.0 - hidden_layer[i]) * (1.0 + hidden_layer[i])\n",
        "    for i in range(0, len(hidden_layer)):\n",
        "        sum_ = 0\n",
        "        for j in range(0, len(output_gradient)):\n",
        "            sum_ += output_gradient[j] * hidden_weights[i][j]\n",
        "        hidden_gradient[i] = sum_ * hidden_derivative[i]\n",
        "    recalculate_weights(learning_rate, hidden_weights, output_gradient, hidden_layer)\n",
        "    recalculate_weights(learning_rate, weights, hidden_gradient, x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "842e987aa6eeab97f21fceb01c49d1465983e9cd",
        "_cell_guid": "9e2dbc9d-0f08-4c0b-94d7-31a4b90dc46c",
        "_kg_hide-input": false,
        "collapsed": true,
        "trusted": false,
        "id": "alGiUP0_Ehe1",
        "outputId": "c28abd77-c31a-4534-8320-285bade2538e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "one_hot_encoding = np.zeros((2,2))\n",
        "for i in range(0, len(one_hot_encoding)):\n",
        "    one_hot_encoding[i][i] = 1\n",
        "training_correct_answers = 0\n",
        "for i in range(0, len(x_train)):\n",
        "    activate_layer(hidden_layer, weights, x_train[i])\n",
        "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
        "    output_layer = soft_max(output_layer)\n",
        "    training_correct_answers += 1 if y_train[i] == np.argmax(output_layer) else 0\n",
        "    back_propagation(hidden_layer, output_layer, one_hot_encoding[int(y_train[i])], -1, x_train[i])\n",
        "print(\"MLP Correct answers while learning: %s / %s (Accuracy = %s) on %s database.\" % (training_correct_answers, len(x_train),\n",
        "                                                                                       training_correct_answers/len(x_train),\"Duke breast cancer\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Correct answers while learning: 56 / 77 (Accuracy = 0.7272727272727273) on Duke breast cancer database.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_kg_hide-output": false,
        "_uuid": "d054f30b2e1514d48825906f72a667ae139dddda",
        "_cell_guid": "3e97419b-e5b8-4751-b1aa-b92adbdb7883",
        "collapsed": true,
        "trusted": false,
        "id": "BMEVFJehEhe1",
        "outputId": "3c6665e1-53c3-4a6c-d8f2-7e8985442296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "testing_correct_answers = 0\n",
        "for i in range(0, len(x_test)):\n",
        "    activate_layer(hidden_layer, weights, x_test[i])\n",
        "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
        "    output_layer = soft_max(output_layer)\n",
        "    testing_correct_answers += 1 if y_test[i] == np.argmax(output_layer) else 0\n",
        "print(\"MLP Correct answers while testing: %s / %s (Accuracy = %s) on %s database\" % (testing_correct_answers, len(x_test),\n",
        "                                                                                     testing_correct_answers/len(x_test), \"Duke breast cancer\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Correct answers while testing: 5 / 9 (Accuracy = 0.5555555555555556) on Duke breast cancer database\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Back-Propagation Neural Network",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}